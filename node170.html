<!DOCTYPE html>

<!--Converted with LaTeX2HTML 99.2beta6 (1.42)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
<head>
<title>算法</title>
<meta charset="utf-8">
<meta name="description" content="算法">
<meta name="keywords" content="book, math, eigenvalue, eigenvector, linear algebra, sparse matrix">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        var math_displays = document.getElementsByClassName("math-display");
        for (var i = 0; i < math_displays.length; i++) {
            katex.render(math_displays[i].textContent, math_displays[i], { displayMode: true, throwOnError: false });
        }
        var math_inlines = document.getElementsByClassName("math-inline");
        for (var i = 0; i < math_inlines.length; i++) {
            katex.render(math_inlines[i].textContent, math_inlines[i], { displayMode: false, throwOnError: false });
        }
    });
</script>
<style>
    .navigate {
        background-color: #ffffff;
        border: 1px solid black;
        color: black;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 18px;
        margin: 4px 2px;
        cursor: pointer;
        border-radius: 4px;
    }
    .crossref {
        width: 10pt;
        height: 10pt;
        border: 1px solid black;
        padding: 0;
    }
    .algorithm {
        font-family: inherit;
        font-size: inherit;
        white-space: pre-wrap;
        border: 1px solid #ddd;
    }
</style>
</head>

<body >
<!--Navigation Panel-->
<a name="tex2html3321"
  href="node171.html">
<button class="navigate">下一节</button></a> 
<a name="tex2html3315"
  href="node169.html">
<button class="navigate">上一级</button></a> 
<a name="tex2html3309"
  href="node169.html">
<button class="navigate">上一节</button></a> 
<a name="tex2html3317"
  href="node5.html">
<button class="navigate">目录</button></a> 
<a name="tex2html3319"
  href="node422.html">
<button class="navigate">索引</button></a> 
<br>
<b>下一节：</b><a name="tex2html3322" href="node171.html">带SI的Lanczos算法</a>
<b>上一级：</b><a name="tex2html3316" href="node169.html">Lanczos方法</a>
<b>上一节：</b><a name="tex2html3310" href="node169.html">Lanczos方法</a>
<br>
<br>
<!--End of Navigation Panel--><h4><a name="SECTION001450010000000000000">
算法</a>
</h4>

在直接迭代变体中，
我们用<span class="math-inline">A</span>进行乘法运算并解<span class="math-inline">B</span>的线性系统；
这对应于<span class="math-inline">C=B^{-1}A</span>。它计算一个
基<span class="math-inline">V_j</span>，其中矩阵束<span class="math-inline">\{A,B\}</span>由一个
实对称三对角矩阵表示，

<div class="math-display" id="gen_tridia">
T_{j}=\begin{bmatrix}
\alpha_1 & \beta_1 & & \\
\beta_1 & \alpha_2 & \ddots & \\
& \ddots & \ddots & \beta_{j-1}\\
& & \beta_{j-1} & \alpha_j
\end{bmatrix}, \tag{5.8}
</div>

满足基本递归关系，

<div class="math-display" id="gen-herm-recursion">AV_j=BV_{j}T_{j}+re_j^{\ast}. \tag{5.9}</div>

与标准厄米特情况（<a href="node103.html#herm-recursion">4.10</a>）相比较。
现在基<span class="math-inline">V_j</span>是<span class="math-inline">B</span>-正交的，

<div class="math-display" id="B-ortho">V_j^{\ast}BV_j=I_{j}, \tag{5.10}</div>

且矩阵<span class="math-inline">T</span>与<span class="math-inline">A</span>的一个截面是相合的，

<div class="math-display" id="T_section">V_j^{\ast}AV_j=T_{j}. \tag{5.11}</div>


<p>
我们通过引入一个辅助基来简化<span class="math-inline">B</span>-正交化的描述，

<div class="math-display" id="w-basis">W_j=BV_j, \tag{5.12}</div>

它是<span class="math-inline">B^{-1}</span>-正交的，

<div class="math-display" id="B-w-ortho">W_j^{\ast}B^{-1}W_j=I_{j}, \tag{5.13}</div>

并且对于它，<span class="math-inline">W^{\ast}V=I</span>。

<p>
正如标准情况一样，
计算<span class="math-inline">T_{j}</span>的特征解，


<div class="math-display">T_{j}s_i^{(j)}=s_i^{(j)}\theta_i^{(j)},</div>

并得到一个
Ritz 值
<span class="math-inline">\theta_i^{(j)}</span> 和一个 Ritz 向量，

<div class="math-display" id="gen_eigenvector">x_i^{(j)}=V_js_i^{(j)}, \tag{5.14}</div>

近似于束的特征对（<a href="node156.html#gsymeig">5.1</a>）。
其残差，

<div class="math-display">
\begin{aligned}
r_i^{(j)} &= Ax_i^{(j)}-Bx_i^{(j)}\theta_i^{(j)}=AV_js_i^{(j)}- BV_js_i^{(j)}\theta_i^{(j)} \\
&= (AV_j-BV_jT_j)s_i^{(j)} = r e^*_j s_i^{(j)} = Bv_{j+1}\beta_js_{j,i}^{(j)},
\end{aligned}
</div>

是<span class="math-inline">B</span>-正交于由<span class="math-inline">V_j</span>张成的Krylov空间。

<p>
我们可以像在标准厄米特情况中那样估计残差的范数（<a href="node103.html#estimate_residual">4.13</a>），但现在使用<span class="math-inline">B^{-1}</span>-范数会更好，得到

<div class="math-display" id="gen_estimate_residual">\Vert r_i^{(j)}\Vert _{B^{-1}}=\vert\beta_js_{j,i}^{(j)}\vert\;, \tag{79}</div>

利用了事实
<span class="math-inline">(Bv_{j+1})^{\ast}B^{-1}(Bv_{j+1})=v_{j+1}^{\ast}Bv_{j+1}</span>。
在衡量收敛性时自然使用<span class="math-inline">B^{-1}</span>-范数；
参见[<a
 href="node421.html#parl80">353</a>, Chap.&nbsp;15]。

<p>
与标准情况一样，我们需要
监控<span class="math-inline">T</span>的次对角元素<span class="math-inline">\beta_j</span>，
以及其特征向量的最后一个元素<span class="math-inline">s_{j,i}^{(j)}</span>。一旦这个
乘积变小，我们就可以标记一个特征值为收敛，
而不必实际执行矩阵-向量
乘法（<a href="node170.html#gen_eigenvector">5.14</a>）。我们保存这个
操作直到步骤<span class="math-inline">j</span>，那时估计（<a href="node170.html#gen_estimate_residual">5.15</a>）
指示收敛。

<p>

<p>
<br>

<p>
我们得到以下算法。

<a name="gen_approximate_eigenvectors"></a><a name="gen_convergence"></a><a name="gen_approximate_eigenvalues"></a><a name="B_solve"></a><a name="gen_Reorthogonalize"></a><a name="gen_Operate"></a><a name="gen_h_starting_vector"></a><a name="Gen_Herm_Lanczos"></a>
<pre class="algorithm">
算法 5.4 GHEP的Lanczos方法
(1)  取初始向量 <span class="math-inline">q</span>，计算 <span class="math-inline">r = Bq,\; \beta_0 = \vert q^*r\vert^{1/2}</span>
(2)  for <span class="math-inline">j = 1,2,\dots,</span>
(3)      <span class="math-inline">w_j = r/\beta_{j-1}, v_j = q/\beta_{j-1}</span>
(4)      <span class="math-inline">r = Av</span>
(5)      <span class="math-inline">r = r - w_{j-1}\beta_{j-1}</span>
(6)      <span class="math-inline">\alpha_j = v_j^*r</span>
(7)      <span class="math-inline">r = r - w_j \alpha_j</span>
(8)      如果需要，重正交化
(9)      解 <span class="math-inline">Bq = r</span> 得到 <span class="math-inline">q</span>
(10)     <span class="math-inline">\beta_j = \vert q^* r\vert^{1/2}</span>
(11)     计算 <span class="math-inline">T_j</span> 的特征分解 <span class="math-inline">T_j = S \Theta^{(j)} S^*</span>
(12)     如果收敛，停止
(13) end for
(14) 计算特征向量 <span class="math-inline">x_i^{(j)} = V_js_i^{(j)}</span>，对于每个收敛的 <span class="math-inline">i</span>
</pre>


<p>
让我们一步一步地评论这个算法：
<dl>
<dt><strong>(1)</strong></dt>
<dd>如果有一个好的想要的特征向量的猜测，就用它作为
起始<span class="math-inline">q</span>。在其他情况下选择一个随机方向，例如，
由正态分布的随机数组成。注意

<span class="math-inline">\alpha_1=q^{\ast}Aq/(q^{\ast}Bq)</span>是起始向量的Rayleigh商，而<span class="math-inline">\beta_1</span>测量其
残差的<span class="math-inline">B^{-1}</span>-范数（<a href="node170.html#gen_estimate_residual">5.15</a>）。

<p>
</dd>
<dt><strong>(4)</strong></dt>
<dd>这是大矩阵<span class="math-inline">A</span>出现的地方。
任何执行矩阵-向量乘法的例程都可以使用。

<p>
</dd>
<dt><strong>(8)</strong></dt>
<dd>只需重新正交化基<span class="math-inline">V</span>或<span class="math-inline">W</span>中的一个，
而不是两者。
选择与标准情况相同：
<a name="17420"></a>

<ol>
<li><em>完全：</em>
现在我们希望使<span class="math-inline">v</span>基向量<span class="math-inline">B</span>-正交，
计算

<div class="math-display">r=r-B(V_j(V_j^{\ast}r))</div>

并重复直到向量<span class="math-inline">r</span>与基<span class="math-inline">V_j</span>正交。
我们必须为每次重新正交化应用一次<span class="math-inline">B</span>的矩阵-向量乘法，并且必须使用经典
的Gram-Schmidt过程。

<p>
如果我们保存两个基<span class="math-inline">V_j</span>和<span class="math-inline">W_j</span>并减去<span class="math-inline">W_j</span>的列的倍数，

<div class="math-display">r=r-W_j(V_j^{\ast}r),</div>

直到正交性获得，几乎总是只需一次。
现在我们可以使用改进的Gram-Schmidt正交化。

<p>
</li>
<li><em>选择性：</em>仅在必要时重新正交化，
必须监控正交性，如
§<a href="node108.html#select-ort">4.4.4</a>中所述
对于标准情况。注意现在对称矩阵

<span class="math-inline">V_j^{\ast}W_j=V_j^{\ast}BV_j</span>涉及其中，一些向量<span class="math-inline">v_k</span>
必须由相应的向量<span class="math-inline">w_k</span>替换。
</li>
<li><em>局部：</em>用于巨大的矩阵，当存储
整个基<span class="math-inline">V_j</span>很困难时。仅在寻找一个或两个极端特征值时才建议使用。我们确保<span class="math-inline">w_{j+1}</span>与<span class="math-inline">v_{j-1}</span>和
<span class="math-inline">v_j</span>正交，通过减去
<span class="math-inline">r=r-w_{j-1}(v_{j-1}^{\ast}r); r=r-w_j(v_j^{\ast}r)</span>一次
在这一步。
</li>
</ol>
</dd>
<dt><strong>(9)</strong></dt>
<dd>在这里我们需要解一个正定矩阵<span class="math-inline">B</span>的系统。这在标准情况中
（<a href="node86.html#symeig">4.1</a>）是不需要的。
</dd>
<dt><strong>(11)</strong></dt>
<dd>对于每个步骤<span class="math-inline">j</span>，或在适当的间隔，
计算对称三对角矩阵
<span class="math-inline">T_{j}</span>（<a href="node170.html#gen_tridia">5.8</a>）的特征值
<span class="math-inline">\theta_i^{(j)}</span>和特征向量<span class="math-inline">s_i^{(j)}</span>。与标准情况相同的过程。

<p>
</dd>
<dt><strong>(12)</strong></dt>
<dd>当找到一个足够大的基<span class="math-inline">V_j</span>时，算法停止，
使得三对角矩阵<span class="math-inline">T_{j}</span>（<a href="node170.html#gen_tridia">5.8</a>）的特征值
<span class="math-inline">\theta_i^{(j)}</span>给出束（<a href="node156.html#gsymeig">5.1</a>）的所有
特征值的良好近似。

<p>
如果基
<span class="math-inline">V_j</span>不是完全<span class="math-inline">B</span>-正交的，估计（<a href="node170.html#gen_estimate_residual">5.15</a>）对于残差
可能过于乐观。
那么Ritz向量<span class="math-inline">x_i^{(j)}</span>（<a href="node170.html#gen_eigenvector">5.14</a>）可能具有范数
小于<span class="math-inline">1</span>，我们必须用以下估计替换，

<div class="math-display">\Vert r_i^{(j)}\Vert=\vert\beta_js_{j,i}^{(j)}\vert/\Vert V_js_i^{(j)}\Vert _B\;.</div>

<p>
</dd>
<dt><strong>(14)</strong></dt>
<dd>只有在步骤（<a href="node170.html#gen_convergence">5.4</a>）中的测试指示它们
已经收敛时，才计算原始矩阵束（<a href="node156.html#gsymeig">5.1</a>）的特征向量。然后基<span class="math-inline">V_j</span>用于矩阵-向量
乘法以得到
特征向量（<a href="node170.html#gen_eigenvector">5.14</a>），

<div class="math-display">x_i^{(j)}=V_js_i^{(j)},</div>

对于每个标记为收敛的<span class="math-inline">i</span>。

<p>
</dd>
</dl>

<p>
<hr><!--Navigation Panel-->
<a name="tex2html3321"
  href="node171.html">
<button class="navigate">下一节</button></a> 
<a name="tex2html3315"
  href="node169.html">
<button class="navigate">上一级</button></a> 
<a name="tex2html3309"
  href="node169.html">
<button class="navigate">上一节</button></a> 
<a name="tex2html3317"
  href="node5.html">
<button class="navigate">目录</button></a> 
<a name="tex2html3319"
  href="node422.html">
<button class="navigate">索引</button></a> 
<br>
<b>下一节：</b><a name="tex2html3322" href="node171.html">带SI的Lanczos算法</a>
<b>上一级：</b><a name="tex2html3316" href="node169.html">Lanczos方法</a>
<b>上一节：</b><a name="tex2html3310" href="node169.html">Lanczos方法</a>
<!--End of Navigation Panel-->
<address>
Susan Blackford
2000-11-20
</address>
</body>
</html>
